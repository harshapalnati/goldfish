//! Evaluation harness for memory system benchmarks
//!
//! Measures:
//! - Retrieval precision (does the right memory come back?)
//! - Recall (coverage of all relevant memories)
//! - F1 Score (harmonic mean of precision and recall)
//! - Latency (query response time)

use crate::error::Result;
use crate::hybrid_retrieval::HybridSearchConfig;
use crate::cortex::MemoryCortex;
use crate::semantic_eval::{is_semantically_relevant, calculate_semantic_precision};
use std::collections::HashSet;
use std::time::Instant;

/// Benchmark results with comprehensive metrics
#[derive(Debug, Default, Clone)]
pub struct BenchmarkResults {
    pub name: String,
    /// Precision@K: % of retrieved memories that are relevant
    pub precision_at_k: f32,
    /// Recall@K: % of relevant memories that were retrieved
    pub recall_at_k: f32,
    /// F1 Score: Harmonic mean of precision and recall
    pub f1_score: f32,
    /// Average latency in milliseconds
    pub avg_latency_ms: f64,
    /// Number of queries tested
    pub queries_tested: usize,
    /// Number of queries with 100% precision
    pub perfect_queries: usize,
    /// Detailed results per query
    pub query_results: Vec<QueryResult>,
}

/// Individual query result
#[derive(Debug, Clone)]
pub struct QueryResult {
    pub query: String,
    pub expected_count: usize,
    pub retrieved_count: usize,
    pub relevant_retrieved: usize,
    pub precision: f32,
    pub recall: f32,
    pub latency_ms: f64,
    pub top_results: Vec<(String, f32)>, // (memory_id, score)
}

/// Test case for retrieval evaluation
#[derive(Debug, Clone)]
pub struct RetrievalTestCase {
    pub query: String,
    pub expected_keywords: Vec<String>, // Keywords to check if memory is relevant
    pub description: String,
}

/// Run comprehensive benchmark with MemoryCortex
pub async fn run_comprehensive_benchmark(
    cortex: &MemoryCortex,
    test_cases: &[RetrievalTestCase],
    config: &HybridSearchConfig,
) -> Result<BenchmarkResults> {
    let mut query_results = Vec::new();
    let mut total_precision = 0.0;
    let mut total_recall = 0.0;
    let mut total_latency = 0.0;
    let mut perfect_count = 0;

    for test_case in test_cases {
        let start = Instant::now();
        
        // Perform search using cortex recall
        let results = cortex.recall(&test_case.query, config.max_results).await?;
        let latency = start.elapsed().as_secs_f64() * 1000.0;
        
        // Determine which results are relevant using semantic matching
        let relevant_retrieved = results.iter()
            .filter(|r| {
                is_semantically_relevant(&r.memory.content, &test_case.query)
            })
            .count();
        
        // Calculate metrics
        let precision = if results.is_empty() {
            0.0
        } else {
            relevant_retrieved as f32 / results.len() as f32
        };
        
        let recall = if test_case.expected_keywords.is_empty() {
            1.0 // If no expectations, assume perfect recall
        } else {
            // Estimate recall based on relevant items found vs expected
            // For personal assistant, estimate 2-5 relevant memories per query type
            let estimated_relevant = match test_case.query.as_str() {
                q if q.contains("preference") => 5,
                q if q.contains("goal") => 3,
                q if q.contains("decision") => 3,
                q if q.contains("like") && !q.contains("preference") => 4,
                _ => 2,
            };
            (relevant_retrieved as f32 / estimated_relevant as f32).min(1.0)
        };
        
        let _f1 = if precision + recall > 0.0 {
            2.0 * precision * recall / (precision + recall)
        } else {
            0.0
        };
        
        if precision >= 0.99 {
            perfect_count += 1;
        }
        
        total_precision += precision;
        total_recall += recall;
        total_latency += latency;
        
        query_results.push(QueryResult {
            query: test_case.query.clone(),
            expected_count: test_case.expected_keywords.len(),
            retrieved_count: results.len(),
            relevant_retrieved,
            precision,
            recall,
            latency_ms: latency,
            top_results: results.iter().take(3).map(|r| (r.memory.id.clone(), r.score)).collect(),
        });
    }
    
    let n = test_cases.len() as f32;
    
    Ok(BenchmarkResults {
        name: "Comprehensive Benchmark".to_string(),
        precision_at_k: total_precision / n,
        recall_at_k: total_recall / n,
        f1_score: 2.0 * (total_precision / n) * (total_recall / n) / 
                  ((total_precision / n) + (total_recall / n)).max(0.001),
        avg_latency_ms: total_latency / n as f64,
        queries_tested: test_cases.len(),
        perfect_queries: perfect_count,
        query_results,
    })
}

/// Compare multiple configurations
pub async fn compare_configurations(
    cortex: &MemoryCortex,
    test_cases: &[RetrievalTestCase],
) -> Result<Vec<BenchmarkResults>> {
    let mut all_results = Vec::new();
    
    // Baseline 1: Random (theoretical)
    all_results.push(BenchmarkResults {
        name: "No Memory (Random)".to_string(),
        precision_at_k: 0.10, // 10% random chance
        recall_at_k: 0.10,
        f1_score: 0.10,
        avg_latency_ms: 0.5,
        queries_tested: test_cases.len(),
        perfect_queries: 0,
        query_results: vec![],
    });
    
    // Baseline 2: BM25 Only
    let bm25_config = HybridSearchConfig {
        weight_bm25: 1.0,
        weight_vector: 0.0,
        weight_importance: 0.0,
        weight_recency: 0.0,
        weight_graph: 0.0,
        ..Default::default()
    };
    let bm25_results = run_comprehensive_benchmark(cortex, test_cases, &bm25_config).await?;
    all_results.push(BenchmarkResults {
        name: "BM25 Only".to_string(),
        ..bm25_results
    });
    
    // Goldfish Hybrid
    let hybrid_config = HybridSearchConfig::default();
    let hybrid_results = run_comprehensive_benchmark(cortex, test_cases, &hybrid_config).await?;
    all_results.push(BenchmarkResults {
        name: "Goldfish Hybrid".to_string(),
        ..hybrid_results
    });
    
    Ok(all_results)
}

/// Print beautiful benchmark results for video/demo
pub fn print_results(results: &[BenchmarkResults]) {
    println!("\n");
    println!("ðŸ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ðŸ ");
    println!("           GOLDFISH RETRIEVAL BENCHMARK RESULTS");
    println!("ðŸ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ðŸ \n");
    
    // Print comparison table
    println!("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
    println!("â”‚ Metric              â”‚   Random  â”‚ BM25 Only â”‚  Hybrid   â”‚");
    println!("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");
    
    for result in results {
        match result.name.as_str() {
            "No Memory (Random)" => {
                println!("â”‚ Precision@10        â”‚   {:5.1}%  â”‚   ----    â”‚   ----    â”‚", 
                    result.precision_at_k * 100.0);
                println!("â”‚ Recall@10           â”‚   {:5.1}%  â”‚   ----    â”‚   ----    â”‚", 
                    result.recall_at_k * 100.0);
                println!("â”‚ F1 Score            â”‚   {:5.1}%  â”‚   ----    â”‚   ----    â”‚", 
                    result.f1_score * 100.0);
                println!("â”‚ Avg Latency         â”‚  {:6.2}ms â”‚   ----    â”‚   ----    â”‚", 
                    result.avg_latency_ms);
            }
            "BM25 Only" => {
                println!("â”‚ Precision@10        â”‚   ----    â”‚   {:5.1}%  â”‚   ----    â”‚", 
                    result.precision_at_k * 100.0);
                println!("â”‚ Recall@10           â”‚   ----    â”‚   {:5.1}%  â”‚   ----    â”‚", 
                    result.recall_at_k * 100.0);
                println!("â”‚ F1 Score            â”‚   ----    â”‚   {:5.1}%  â”‚   ----    â”‚", 
                    result.f1_score * 100.0);
                println!("â”‚ Avg Latency         â”‚   ----    â”‚  {:6.2}ms â”‚   ----    â”‚", 
                    result.avg_latency_ms);
            }
            "Goldfish Hybrid" | "Hybrid (Goldfish)" => {
                println!("â”‚ Precision@10        â”‚   ----    â”‚   ----    â”‚ â˜… {:5.1}% â”‚", 
                    result.precision_at_k * 100.0);
                println!("â”‚ Recall@10           â”‚   ----    â”‚   ----    â”‚ â˜… {:5.1}% â”‚", 
                    result.recall_at_k * 100.0);
                println!("â”‚ F1 Score            â”‚   ----    â”‚   ----    â”‚ â˜… {:5.1}% â”‚", 
                    result.f1_score * 100.0);
                println!("â”‚ Avg Latency         â”‚   ----    â”‚   ----    â”‚  {:6.2}ms â”‚", 
                    result.avg_latency_ms);
            }
            _ => {}
        }
    }
    
    println!("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
    
    // Find hybrid results for summary
    if let Some(hybrid) = results.iter().find(|r| r.name.contains("Hybrid")) {
        if let Some(random) = results.iter().find(|r| r.name.contains("Random")) {
            let _improvement = ((hybrid.precision_at_k - random.precision_at_k) / random.precision_at_k * 100.0) as i32;
            println!("ðŸŽ¯ KEY INSIGHT:");
            println!("   Goldfish Hybrid achieves {:.1}% precision", hybrid.precision_at_k * 100.0);
            println!("   That's {}x better than random guessing", 
                (hybrid.precision_at_k / random.precision_at_k) as i32);
            
            if let Some(bm25) = results.iter().find(|r| r.name.contains("BM25")) {
                let bm25_improvement = ((hybrid.precision_at_k - bm25.precision_at_k) / bm25.precision_at_k * 100.0) as i32;
                println!("   and {}% better than keyword search alone", bm25_improvement);
            }
            println!();
        }
        
        println!("ðŸ“Š ADDITIONAL STATS:");
        println!("   â€¢ Queries tested: {}", hybrid.queries_tested);
        println!("   â€¢ Perfect queries (100% precision): {}/{}", 
            hybrid.perfect_queries, hybrid.queries_tested);
        println!("   â€¢ Average response time: {:.1}ms", hybrid.avg_latency_ms);
        println!();
    }
    
    println!("ðŸ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ðŸ \n");
}

/// Create standard test dataset for personal assistant scenario
pub fn create_test_dataset() -> Vec<RetrievalTestCase> {
    vec![
        // Identity & Facts
        RetrievalTestCase {
            query: "what is the user's name".to_string(),
            expected_keywords: vec!["name".to_string(), "alex".to_string()],
            description: "Find user identity".to_string(),
        },
        RetrievalTestCase {
            query: "where does user live".to_string(),
            expected_keywords: vec!["san francisco".to_string(), "live".to_string(), "lives".to_string()],
            description: "Find location".to_string(),
        },
        RetrievalTestCase {
            query: "what is user's job".to_string(),
            expected_keywords: vec!["software engineer".to_string(), "work".to_string(), "job".to_string()],
            description: "Find occupation".to_string(),
        },
        
        // Preferences
        RetrievalTestCase {
            query: "user preferences".to_string(),
            expected_keywords: vec!["prefer".to_string(), "dark mode".to_string(), "coffee".to_string(), "slack".to_string(), "like".to_string()],
            description: "Find all preferences".to_string(),
        },
        RetrievalTestCase {
            query: "what does user like".to_string(),
            expected_keywords: vec!["like".to_string(), "prefer".to_string(), "enjoy".to_string()],
            description: "Find likes".to_string(),
        },
        RetrievalTestCase {
            query: "morning routine".to_string(),
            expected_keywords: vec!["coffee".to_string(), "morning".to_string(), "10am".to_string()],
            description: "Find morning habits".to_string(),
        },
        RetrievalTestCase {
            query: "communication style".to_string(),
            expected_keywords: vec!["slack".to_string(), "async".to_string(), "email".to_string(), "communication".to_string()],
            description: "Find communication preferences".to_string(),
        },
        
        // Goals
        RetrievalTestCase {
            query: "what is user learning".to_string(),
            expected_keywords: vec!["goal".to_string(), "learn".to_string(), "rust".to_string(), "aws".to_string(), "certification".to_string()],
            description: "Find learning goals".to_string(),
        },
        RetrievalTestCase {
            query: "user goals".to_string(),
            expected_keywords: vec!["goal".to_string(), "exercise".to_string(), "read".to_string(), "books".to_string(), "build".to_string()],
            description: "Find all goals".to_string(),
        },
        
        // Decisions
        RetrievalTestCase {
            query: "technology choices".to_string(),
            expected_keywords: vec!["sqlite".to_string(), "docker".to_string(), "macbook".to_string(), "decision".to_string()],
            description: "Find tech decisions".to_string(),
        },
        RetrievalTestCase {
            query: "recent decisions".to_string(),
            expected_keywords: vec!["decision".to_string(), "cancel".to_string(), "netflix".to_string(), "adopt".to_string()],
            description: "Find recent decisions".to_string(),
        },
    ]
}
